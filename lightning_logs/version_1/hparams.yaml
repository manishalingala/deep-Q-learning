batch_size: 256
capacity: 1000000
eps_end: 0.15
eps_last_episode: 100
eps_start: 1.0
gamma: 0.99
hidden_size: 128
loss_fn: !!python/name:torch.nn.functional.smooth_l1_loss ''
lr: 0.001
optim: !!python/name:torch.optim.adamw.AdamW ''
policy: !!python/name:__main__.epsilon_greedy ''
samples_per_epoch: 10000
sync_rate: 10
